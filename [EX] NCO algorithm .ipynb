{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo NCO\n",
    "\n",
    "Este algoritmo surge con la idea de reducir las fuentes de inestabilidad implícitas en la matriz de covarianzas. Por un lado, lidia con el ruido y por el otro, con la señal, responsable de magnificar los errores de estimación en las variables de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "\n",
    "import requests, json\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import cvxpy as cp\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "#from scipy.cluster.hierarchy import ClusterWarning\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", FutureWarning)\n",
    "simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de datos\n",
    "\n",
    "En este notebook vamos a hacer una prueba con un número reducido de tickers seleccionados al azar. La idea es, una vez esté bien definido el comportamiento del algoritmo, definir una función en el notebook de \"Portfolio rebalance\" que calcule los pesos partiendo únicamente del dataframe con los rendimientos diarios de los tickers a considerar. \n",
    "\n",
    "Descargamos primero los precios de cierre diarios de todas las empresas del IBEX 35 recogidas en la API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Función que permite obtener un dataframe con los precios de cierre de todos los tickers que pertenecen o han pertenecido al\n",
    "índice introducido como parámetro (benchmark_name).\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    benchmark_name (string) -> indica el índice a considerar ('IBEX', 'DAX' o 'EUROSTOXX').\n",
    "    \n",
    "DATOS DE SALIDA:\n",
    "    df (dataframe) -> precios de cierre de todos los tickers que pertenecen o han pertenecido al índice introducido \n",
    "                      como parámetro (benchmark_name).\n",
    "'''\n",
    "\n",
    "def get_data(benchmark_name):\n",
    "    \n",
    "    url_base = 'https://miax-gateway-jog4ew3z3q-ew.a.run.app'\n",
    "    headers = {'Content-Type': 'application/json'}    \n",
    "    competi = 'mia_4'\n",
    "    user_key = 'AIzaSyAtcbexO5rwPBXet_P1tBxvC4BHYZHJAbs'\n",
    "    \n",
    "    url = f'{url_base}/data/ticker_master'\n",
    "\n",
    "    # MAESTRA DE VALORES:\n",
    "    params = {'competi': competi,\n",
    "              'market': benchmark_name,\n",
    "              'key': user_key}\n",
    "    response = requests.get(url, params)\n",
    "    tk_master = response.json()\n",
    "    \n",
    "    maestro_df = pd.DataFrame(tk_master['master'])\n",
    "    lista=maestro_df['ticker'].tolist()\n",
    "\n",
    "    # En la maestra no están incluidos todos los tickers del IBEX:\n",
    "    if benchmark_name=='IBEX':\n",
    "        lista.append('FDR')\n",
    "        lista.append('SLR')\n",
    "\n",
    "    # PRECIOS:\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    url2 = f'{url_base}/data/time_series'\n",
    "    \n",
    "    for i in range(len(lista)):\n",
    "        params = {'market': benchmark_name,\n",
    "                  'key': user_key,\n",
    "                  'ticker': lista[i],\n",
    "                  'close': False}\n",
    "        response = requests.get(url2, params)\n",
    "        tk_data = response.json()\n",
    "    \n",
    "        if response.status_code == 200:\n",
    "            df_data = pd.read_json(tk_data, typ='frame')\n",
    "        else: \n",
    "            print(response.text)\n",
    "            \n",
    "        precios=df_data['close']\n",
    "        df=pd.concat([df,precios], ignore_index=False, axis=1).rename(columns={'close': lista[i]})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABE</th>\n",
       "      <th>ABG</th>\n",
       "      <th>ABG.P_0</th>\n",
       "      <th>ABG.P_1</th>\n",
       "      <th>ACS</th>\n",
       "      <th>ACX</th>\n",
       "      <th>ACX_0</th>\n",
       "      <th>AENA</th>\n",
       "      <th>ALM</th>\n",
       "      <th>AMS</th>\n",
       "      <th>...</th>\n",
       "      <th>SCYR_1</th>\n",
       "      <th>SGRE</th>\n",
       "      <th>SGRE_0</th>\n",
       "      <th>TEF</th>\n",
       "      <th>TL5</th>\n",
       "      <th>TRE</th>\n",
       "      <th>VIS</th>\n",
       "      <th>VIS_0</th>\n",
       "      <th>FDR</th>\n",
       "      <th>SLR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>7.079902</td>\n",
       "      <td>3.9889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.198652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.722429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.381871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.364632</td>\n",
       "      <td>9.046801</td>\n",
       "      <td>6.904748</td>\n",
       "      <td>29.693987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>7.110934</td>\n",
       "      <td>3.9813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.518600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.797462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.496363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.544552</td>\n",
       "      <td>9.033079</td>\n",
       "      <td>6.938567</td>\n",
       "      <td>30.546259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>7.137689</td>\n",
       "      <td>4.0098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.556553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.755071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.552471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.624838</td>\n",
       "      <td>8.966899</td>\n",
       "      <td>6.904748</td>\n",
       "      <td>29.882358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>7.077627</td>\n",
       "      <td>4.0368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.371189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.807211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.629802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.666842</td>\n",
       "      <td>8.877849</td>\n",
       "      <td>6.993000</td>\n",
       "      <td>30.283471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>7.008919</td>\n",
       "      <td>3.9922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.772204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.813826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.026540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.708928</td>\n",
       "      <td>8.722548</td>\n",
       "      <td>7.064299</td>\n",
       "      <td>30.187564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.850000</td>\n",
       "      <td>11.480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.15</td>\n",
       "      <td>14.04</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.257000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.75</td>\n",
       "      <td>16.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.860000</td>\n",
       "      <td>11.520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.20</td>\n",
       "      <td>14.38</td>\n",
       "      <td>51.72</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.181500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.60</td>\n",
       "      <td>16.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.510000</td>\n",
       "      <td>11.515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.10</td>\n",
       "      <td>14.63</td>\n",
       "      <td>53.12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.230500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.65</td>\n",
       "      <td>16.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.460000</td>\n",
       "      <td>11.475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.50</td>\n",
       "      <td>14.73</td>\n",
       "      <td>52.84</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.193500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.80</td>\n",
       "      <td>16.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>11.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.90</td>\n",
       "      <td>14.56</td>\n",
       "      <td>51.40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.123000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.40</td>\n",
       "      <td>17.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2987 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ABE     ABG  ABG.P_0  ABG.P_1        ACS     ACX     ACX_0  \\\n",
       "2010-01-04  7.079902  3.9889      NaN      NaN  18.198652     NaN  9.722429   \n",
       "2010-01-05  7.110934  3.9813      NaN      NaN  18.518600     NaN  9.797462   \n",
       "2010-01-06  7.137689  4.0098      NaN      NaN  18.556553     NaN  9.755071   \n",
       "2010-01-07  7.077627  4.0368      NaN      NaN  18.371189     NaN  9.807211   \n",
       "2010-01-08  7.008919  3.9922      NaN      NaN  18.772204     NaN  9.813826   \n",
       "...              ...     ...      ...      ...        ...     ...       ...   \n",
       "2021-08-30       NaN     NaN      NaN      NaN  22.850000  11.480       NaN   \n",
       "2021-08-31       NaN     NaN      NaN      NaN  22.860000  11.520       NaN   \n",
       "2021-09-01       NaN     NaN      NaN      NaN  23.510000  11.515       NaN   \n",
       "2021-09-02       NaN     NaN      NaN      NaN  23.460000  11.475       NaN   \n",
       "2021-09-03       NaN     NaN      NaN      NaN  23.270000  11.420       NaN   \n",
       "\n",
       "              AENA    ALM    AMS  ...    SCYR_1   SGRE    SGRE_0       TEF  \\\n",
       "2010-01-04     NaN    NaN    NaN  ...  5.381871    NaN  9.364632  9.046801   \n",
       "2010-01-05     NaN    NaN    NaN  ...  5.496363    NaN  9.544552  9.033079   \n",
       "2010-01-06     NaN    NaN    NaN  ...  5.552471    NaN  9.624838  8.966899   \n",
       "2010-01-07     NaN    NaN    NaN  ...  5.629802    NaN  9.666842  8.877849   \n",
       "2010-01-08     NaN    NaN    NaN  ...  6.026540    NaN  9.708928  8.722548   \n",
       "...            ...    ...    ...  ...       ...    ...       ...       ...   \n",
       "2021-08-30  135.15  14.04  50.90  ...       NaN  25.61       NaN  4.257000   \n",
       "2021-08-31  135.20  14.38  51.72  ...       NaN  25.11       NaN  4.181500   \n",
       "2021-09-01  138.10  14.63  53.12  ...       NaN  25.64       NaN  4.230500   \n",
       "2021-09-02  138.50  14.73  52.84  ...       NaN  25.85       NaN  4.193500   \n",
       "2021-09-03  133.90  14.56  51.40  ...       NaN  25.66       NaN  4.123000   \n",
       "\n",
       "                 TL5        TRE    VIS  VIS_0    FDR     SLR  \n",
       "2010-01-04  6.904748  29.693987    NaN    NaN    NaN     NaN  \n",
       "2010-01-05  6.938567  30.546259    NaN    NaN    NaN     NaN  \n",
       "2010-01-06  6.904748  29.882358    NaN    NaN    NaN     NaN  \n",
       "2010-01-07  6.993000  30.283471    NaN    NaN    NaN     NaN  \n",
       "2010-01-08  7.064299  30.187564    NaN    NaN    NaN     NaN  \n",
       "...              ...        ...    ...    ...    ...     ...  \n",
       "2021-08-30       NaN        NaN  60.15    NaN  35.75  16.650  \n",
       "2021-08-31       NaN        NaN  59.80    NaN  34.60  16.800  \n",
       "2021-09-01       NaN        NaN  60.15    NaN  35.65  16.995  \n",
       "2021-09-02       NaN        NaN  59.85    NaN  36.80  16.890  \n",
       "2021-09-03       NaN        NaN  59.70    NaN  36.40  17.180  \n",
       "\n",
       "[2987 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_name='IBEX'\n",
    "\n",
    "df=get_data(benchmark_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos al azar un subconjunto de ellas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACX</th>\n",
       "      <th>MEL</th>\n",
       "      <th>MTS</th>\n",
       "      <th>REP</th>\n",
       "      <th>SAB</th>\n",
       "      <th>TEF</th>\n",
       "      <th>SAN</th>\n",
       "      <th>BBVA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>8.562145</td>\n",
       "      <td>7.415</td>\n",
       "      <td>15.175328</td>\n",
       "      <td>11.858381</td>\n",
       "      <td>0.956198</td>\n",
       "      <td>5.714753</td>\n",
       "      <td>3.308239</td>\n",
       "      <td>4.382224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>8.500573</td>\n",
       "      <td>7.370</td>\n",
       "      <td>14.683241</td>\n",
       "      <td>11.816464</td>\n",
       "      <td>0.958304</td>\n",
       "      <td>5.648322</td>\n",
       "      <td>3.279261</td>\n",
       "      <td>4.348145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>8.623717</td>\n",
       "      <td>7.475</td>\n",
       "      <td>15.228902</td>\n",
       "      <td>12.030242</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>5.754275</td>\n",
       "      <td>3.375221</td>\n",
       "      <td>4.415369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>8.678046</td>\n",
       "      <td>7.585</td>\n",
       "      <td>15.447167</td>\n",
       "      <td>12.021858</td>\n",
       "      <td>0.984631</td>\n",
       "      <td>5.705503</td>\n",
       "      <td>3.360494</td>\n",
       "      <td>4.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>8.841031</td>\n",
       "      <td>7.795</td>\n",
       "      <td>15.972985</td>\n",
       "      <td>12.269170</td>\n",
       "      <td>0.989897</td>\n",
       "      <td>5.775298</td>\n",
       "      <td>3.406099</td>\n",
       "      <td>4.465788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30</th>\n",
       "      <td>11.480000</td>\n",
       "      <td>5.996</td>\n",
       "      <td>29.305000</td>\n",
       "      <td>9.896000</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>4.257000</td>\n",
       "      <td>3.123000</td>\n",
       "      <td>5.535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>11.520000</td>\n",
       "      <td>5.916</td>\n",
       "      <td>28.455000</td>\n",
       "      <td>9.705000</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>4.181500</td>\n",
       "      <td>3.127500</td>\n",
       "      <td>5.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>11.515000</td>\n",
       "      <td>6.052</td>\n",
       "      <td>28.345000</td>\n",
       "      <td>9.515000</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>4.230500</td>\n",
       "      <td>3.179500</td>\n",
       "      <td>5.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02</th>\n",
       "      <td>11.475000</td>\n",
       "      <td>5.998</td>\n",
       "      <td>28.665000</td>\n",
       "      <td>9.747000</td>\n",
       "      <td>0.612600</td>\n",
       "      <td>4.193500</td>\n",
       "      <td>3.139500</td>\n",
       "      <td>5.609000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03</th>\n",
       "      <td>11.420000</td>\n",
       "      <td>5.802</td>\n",
       "      <td>28.245000</td>\n",
       "      <td>9.591000</td>\n",
       "      <td>0.598600</td>\n",
       "      <td>4.123000</td>\n",
       "      <td>3.076000</td>\n",
       "      <td>5.568000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ACX    MEL        MTS        REP       SAB       TEF  \\\n",
       "2019-12-02   8.562145  7.415  15.175328  11.858381  0.956198  5.714753   \n",
       "2019-12-03   8.500573  7.370  14.683241  11.816464  0.958304  5.648322   \n",
       "2019-12-04   8.623717  7.475  15.228902  12.030242  0.989418  5.754275   \n",
       "2019-12-05   8.678046  7.585  15.447167  12.021858  0.984631  5.705503   \n",
       "2019-12-06   8.841031  7.795  15.972985  12.269170  0.989897  5.775298   \n",
       "...               ...    ...        ...        ...       ...       ...   \n",
       "2021-08-30  11.480000  5.996  29.305000   9.896000  0.604000  4.257000   \n",
       "2021-08-31  11.520000  5.916  28.455000   9.705000  0.606000  4.181500   \n",
       "2021-09-01  11.515000  6.052  28.345000   9.515000  0.619000  4.230500   \n",
       "2021-09-02  11.475000  5.998  28.665000   9.747000  0.612600  4.193500   \n",
       "2021-09-03  11.420000  5.802  28.245000   9.591000  0.598600  4.123000   \n",
       "\n",
       "                 SAN      BBVA  \n",
       "2019-12-02  3.308239  4.382224  \n",
       "2019-12-03  3.279261  4.348145  \n",
       "2019-12-04  3.375221  4.415369  \n",
       "2019-12-05  3.360494  4.410701  \n",
       "2019-12-06  3.406099  4.465788  \n",
       "...              ...       ...  \n",
       "2021-08-30  3.123000  5.535000  \n",
       "2021-08-31  3.127500  5.547000  \n",
       "2021-09-01  3.179500  5.637000  \n",
       "2021-09-02  3.139500  5.609000  \n",
       "2021-09-03  3.076000  5.568000  \n",
       "\n",
       "[450 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = ['ACX', 'MEL', 'MTS', 'REP', 'SAB', 'TEF', 'SAN', 'BBVA']\n",
    "\n",
    "price=df.iloc[(len(df)-450):len(df)]\n",
    "price=price.loc[:, lista]\n",
    "\n",
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos sus rendimientos diarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACX</th>\n",
       "      <th>MEL</th>\n",
       "      <th>MTS</th>\n",
       "      <th>REP</th>\n",
       "      <th>SAB</th>\n",
       "      <th>TEF</th>\n",
       "      <th>SAN</th>\n",
       "      <th>BBVA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>-0.007191</td>\n",
       "      <td>-0.006069</td>\n",
       "      <td>-0.032427</td>\n",
       "      <td>-0.003535</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>-0.011624</td>\n",
       "      <td>-0.008759</td>\n",
       "      <td>-0.007777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>0.014487</td>\n",
       "      <td>0.014247</td>\n",
       "      <td>0.037162</td>\n",
       "      <td>0.018092</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.018758</td>\n",
       "      <td>0.029263</td>\n",
       "      <td>0.015461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>-0.004838</td>\n",
       "      <td>-0.008476</td>\n",
       "      <td>-0.004363</td>\n",
       "      <td>-0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.027686</td>\n",
       "      <td>0.034040</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.012489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30</th>\n",
       "      <td>-0.009918</td>\n",
       "      <td>-0.013167</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>-0.000808</td>\n",
       "      <td>-0.014682</td>\n",
       "      <td>-0.004443</td>\n",
       "      <td>-0.013582</td>\n",
       "      <td>-0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>-0.013342</td>\n",
       "      <td>-0.029005</td>\n",
       "      <td>-0.019301</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>-0.017735</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>-0.000434</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>-0.019578</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.016225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02</th>\n",
       "      <td>-0.003474</td>\n",
       "      <td>-0.008923</td>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>-0.010339</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>-0.012581</td>\n",
       "      <td>-0.004967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03</th>\n",
       "      <td>-0.004793</td>\n",
       "      <td>-0.032678</td>\n",
       "      <td>-0.014652</td>\n",
       "      <td>-0.016005</td>\n",
       "      <td>-0.022853</td>\n",
       "      <td>-0.016812</td>\n",
       "      <td>-0.020226</td>\n",
       "      <td>-0.007310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ACX       MEL       MTS       REP       SAB       TEF  \\\n",
       "2019-12-02       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2019-12-03 -0.007191 -0.006069 -0.032427 -0.003535  0.002203 -0.011624   \n",
       "2019-12-04  0.014487  0.014247  0.037162  0.018092  0.032468  0.018758   \n",
       "2019-12-05  0.006300  0.014716  0.014332 -0.000697 -0.004838 -0.008476   \n",
       "2019-12-06  0.018781  0.027686  0.034040  0.020572  0.005348  0.012233   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2021-08-30 -0.009918 -0.013167 -0.004247 -0.000808 -0.014682 -0.004443   \n",
       "2021-08-31  0.003484 -0.013342 -0.029005 -0.019301  0.003311 -0.017735   \n",
       "2021-09-01 -0.000434  0.022989 -0.003866 -0.019578  0.021452  0.011718   \n",
       "2021-09-02 -0.003474 -0.008923  0.011289  0.024383 -0.010339 -0.008746   \n",
       "2021-09-03 -0.004793 -0.032678 -0.014652 -0.016005 -0.022853 -0.016812   \n",
       "\n",
       "                 SAN      BBVA  \n",
       "2019-12-02       NaN       NaN  \n",
       "2019-12-03 -0.008759 -0.007777  \n",
       "2019-12-04  0.029263  0.015461  \n",
       "2019-12-05 -0.004363 -0.001057  \n",
       "2019-12-06  0.013571  0.012489  \n",
       "...              ...       ...  \n",
       "2021-08-30 -0.013582 -0.008065  \n",
       "2021-08-31  0.001441  0.002168  \n",
       "2021-09-01  0.016627  0.016225  \n",
       "2021-09-02 -0.012581 -0.004967  \n",
       "2021-09-03 -0.020226 -0.007310  \n",
       "\n",
       "[450 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r=price.pct_change()\n",
    "\n",
    "df_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoise covariance matrix\n",
    "\n",
    "En este apartado se presentan las funciones necesarias para eliminar el ruido en la matriz de covarianzas sin alterar la información asociada a la señal.\n",
    "\n",
    "Se recomienda aplicar este método sobre todo en aquellos casos en los que el cociente entre el número de datos empleados para el cálculo de la matriz de covarianzas (T) y el número de tickers a considerar (N), N/T, es relativamente pequeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Función que calcula la pdf (probability density function) experimental.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    obs (array) -> observaciones a ajustar. Se trata de la diagonal de la matriz diagonalizada (los autovalores).\n",
    "    bWidth (float) -> ancho de banda del núcleo. \"El ancho de banda actúa aquí como un parámetro de suavización, \n",
    "                      controlando el equilibrio entre el sesgo y la varianza en el resultado. Un ancho de banda \n",
    "                      grande conduce a una distribución de densidad muy suave (es decir, con un sesgo alto). \n",
    "                      Un ancho de banda pequeño conduce a una distribución de densidad poco suave (es decir, \n",
    "                      alta varianza)\".\n",
    "    kernel (string) -> núcleo a emplear.\n",
    "    x (array) -> valores en los que se va a evaluar el ajuste del KDE.\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    pdf (serie) -> pdf experimental.\n",
    "'''  \n",
    "def fitKDE(obs,bWidth=.25,kernel='gaussian',x=None):\n",
    "    if len(obs.shape)==1:\n",
    "        obs=obs.reshape(-1,1)       \n",
    "    kde=KernelDensity(kernel=kernel,bandwidth=bWidth).fit(obs)   \n",
    "    if x is None:\n",
    "        x=np.unique(obs).reshape(-1,1)\n",
    "    if len(x.shape)==1:\n",
    "        x=x.reshape(-1,1)        \n",
    "    logProb=kde.score_samples(x)\n",
    "    pdf=pd.Series(np.exp(logProb),index=x.flatten())    \n",
    "    return pdf\n",
    "\n",
    "\n",
    "'''\n",
    "Función que calcula la pdf (probability density function) teórica de Marchenko-Pastur.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    var (float) -> varianza.\n",
    "    q (float) -> q=T/N, siendo T el número de filas y N el número de columnas.\n",
    "    pts (int) -> número de puntos empleados para construir la pdf.\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    pdf (serie) -> pdf teórica de Marchenko-Pastur.\n",
    "'''  \n",
    "def mpPDF(var,q,pts): # q=T/N     \n",
    "    eMin,eMax=var*(1-(1./q)**.5)**2,var*(1+(1./q)**.5)**2\n",
    "    eVal=np.linspace(eMin,eMax,pts)\n",
    "    pdf=q/(2*np.pi*var*eVal)*((eMax-eVal)*(eVal-eMin))**.5\n",
    "    pdf=pd.Series(pdf,index=eVal)\n",
    "    return pdf\n",
    "\n",
    "'''\n",
    "Función que calcula el error entre la pdf experimental y teórica.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    var (float) -> varianza.\n",
    "    eVal (array) -> autovalores de la matriz de correlaciones en cuestión.\n",
    "    q (float) -> q=T/N, siendo T el número de filas y N el número de columnas.\n",
    "    bWidth (float) -> ancho de banda del núcleo. (Se suele fijar en 0.25).\n",
    "    pts (int) -> número de puntos empleados para construir la pdf.\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    sse (float) -> diferencia entre la pdf experimental y la teórica de Marchenko-Pastur.\n",
    "''' \n",
    "def errPDFs(var,eVal,q,bWidth,pts=1000):\n",
    "    pdf0=mpPDF(var,q,pts) # theoretical pdf\n",
    "    pdf1=fitKDE(eVal,bWidth,x=pdf0.index.values) # empirical pdf\n",
    "    sse=np.sum((pdf1-pdf0)**2)\n",
    "    return sse\n",
    "\n",
    "def fun_to_minimize(x, *args):\n",
    "    return errPDFs(x[0], args[0], args[1], args[2])\n",
    "\n",
    "'''\n",
    "Función que recurre al algoritmo KDE para ajustar distribución empírica de autovalores a la distribución de Marcenko-Pastur\n",
    "con el objetivo final de obtener el máximo autovalor asociado al ruido y poder luego separar los autovalores asociados al\n",
    "ruido de los autovalores asociados a la señal.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    eVal (array) -> autovalores de la matriz de correlaciones en cuestión.\n",
    "    q (float) -> q=T/N, siendo T el número de filas y N el número de columnas.\n",
    "    bWidth (float) -> ancho de banda del núcleo. (Se suele fijar en 0.25).\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    eMax (float) -> autovalor máximo asociado al ruido.\n",
    "    var (float) -> varianza que minimiza el error entre la pdf empírica y experimental. Nos permite calcular eMax.\n",
    "'''\n",
    "def findMaxEval(eVal, q, bWidth):\n",
    "    # Buscamos el valor de la varianza que minimiza el error entre la distribución experimental de autovalores y la \n",
    "    #distribución de Marcenko-Pastur:\n",
    "    var_0 = np.array([0.5])\n",
    "    out=minimize(\n",
    "        fun_to_minimize, \n",
    "        var_0, \n",
    "        args=(eVal, q, bWidth),\n",
    "        bounds=((1E-5, 1-1E-5), )\n",
    "    )\n",
    "    if out['success']:\n",
    "        var=out['x'][0] \n",
    "    else:\n",
    "        var=1 \n",
    "    eMax=var*(1+(1./q)**.5)**2\n",
    "    return eMax,var\n",
    "\n",
    "'''\n",
    "Función que calcula la matriz de correlaciones a partir de una matriz de covarianzas dada.\n",
    "'''\n",
    "def cov2corr(cov):\n",
    "    std=np.sqrt(np.diag(cov))\n",
    "    corr=cov/np.outer(std,std)\n",
    "    corr[corr<-1],corr[corr>1]=-1,1\n",
    "    return corr\n",
    "\n",
    "'''\n",
    "Función que calcula la matriz de covarianzas asociada a una matriz de correlaciones.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    std (array) -> raiz cuadrada de la diagonal de la matriz de covarianzas: std=np.diag(cov)**.5\n",
    "'''\n",
    "def corr2cov(corr,std):\n",
    "    cov=corr*np.outer(std,std)\n",
    "    return cov\n",
    "\n",
    "'''\n",
    "Función que calcula los autovalores y autovectores de una matriz hermítica.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    matrix (array) -> matriz de correlaciones en cuestión.\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    eVal (array) -> autovalores de la matriz de correlaciones.\n",
    "    eVec (array) -> autovectores de la matriz de correlaciones.\n",
    "'''\n",
    "def getPCA(matrix):\n",
    "    eVal,eVec=np.linalg.eigh(matrix)\n",
    "    indices=eVal.argsort()[::-1] # arguments for sorting eVal desc (returns the indices that would sort an array)\n",
    "    eVal,eVec=eVal[indices],eVec[:,indices]\n",
    "    eVal=np.diagflat(eVal) # matriz de entrada diagonalizada\n",
    "    return eVal,eVec\n",
    "\n",
    "'''\n",
    "Función que reduce los autovalores asociados al ruido, devolviendo una matriz de correlaciones sin ruido.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    eVal (array) -> autovalores de la matriz de correlaciones.\n",
    "    eVec (array) -> autovectores de la matriz de correlaciones.\n",
    "    nFacts (int) -> posición en la que habría que añadir el mayor autovalor asociado al ruido para seguir preservando\n",
    "                    ese orden decreciente en el array de autovalores.\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    corr1 (array) -> matriz de correlaciones sin ruido.\n",
    "'''\n",
    "def denoisedCorr(eVal,eVec,nFacts):\n",
    "    eVal_=np.diag(eVal).copy()\n",
    "    \n",
    "    # Los autovalores están ordenados de mayor a menor valor. nFacts es la posición en la que habría que añadir el mayor \n",
    "    # autovalor para seguir preservando ese orden decreciente de los autovalores. Los autovalores menores al autovalor \n",
    "    # máximo hay que modificarlos y es lo que se hace en la siguiente línea:\n",
    "    eVal_[nFacts:]=eVal_[nFacts:].sum()/float(eVal_.shape[0]-nFacts)\n",
    "    \n",
    "    # Definimos la nueva matriz diagonal:\n",
    "    eVal_=np.diag(eVal_) # matriz diagonal que contiene los autovalores corregidos (sería la A en la fórmula)\n",
    "    corr1=np.dot(eVec,eVal_).dot(eVec.T) # esta sería la matriz C tilde\n",
    "    corr1=cov2corr(corr1) # y esta la matriz C sin tilde\n",
    "    return corr1\n",
    "\n",
    "'''\n",
    "Función que reduce los autovalores asociados al ruido, devolviendo una matriz de covarianzas sin ruido.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    cov0 (array) -> matriz de covarianzas a la que queremos eliminar el ruido.\n",
    "    eVal (array) -> autovalores de la matriz de correlaciones.\n",
    "    q (float) -> q=T/N, siendo T el número de filas y N el número de columnas.\n",
    "    bWidth (float) -> ancho de banda del núcleo. (Se suele fijar en 0.25).\n",
    "    \n",
    "DATOS DE SALIDA:\n",
    "    cov1 (array) -> matriz de covarianzas sin ruido.\n",
    "'''\n",
    "def deNoiseCov(cov0,q,bWidth):\n",
    "    corr0=cov2corr(cov0)\n",
    "    eVal0,eVec0=getPCA(corr0)\n",
    "    # recurrimos a la función findMaxEval para obtener eMax0 y poder encontrar con ello nFacts0\n",
    "    eMax0,var0=findMaxEval(np.diag(eVal0),q,bWidth)\n",
    "    # Los autovalores de np.diag(eVal0) están ordenados de mayor a menor valor. Con np.diag(eVal0)[::-1] los ordenamos \n",
    "    # de menor a mayor.\n",
    "    nFacts0=eVal0.shape[0]-np.diag(eVal0)[::-1].searchsorted(eMax0)\n",
    "    # nFacts0 es la posición en la que habría que añadir el mayor autovalor para seguir preservando ese orden decreciente\n",
    "    # de los autovalores \n",
    "    corr1=denoisedCorr(eVal0,eVec0,nFacts0)\n",
    "    cov1=corr2cov(corr1,np.diag(cov0)**.5)\n",
    "    return cov1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACX</th>\n",
       "      <th>MEL</th>\n",
       "      <th>MTS</th>\n",
       "      <th>REP</th>\n",
       "      <th>SAB</th>\n",
       "      <th>TEF</th>\n",
       "      <th>SAN</th>\n",
       "      <th>BBVA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACX</th>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEL</th>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTS</th>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REP</th>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAB</th>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEF</th>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAN</th>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBVA</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ACX       MEL       MTS       REP       SAB       TEF       SAN  \\\n",
       "ACX   0.000529  0.000557  0.000493  0.000421  0.000566  0.000335  0.000434   \n",
       "MEL   0.000557  0.001729  0.000876  0.000747  0.001006  0.000595  0.000771   \n",
       "MTS   0.000493  0.000876  0.001268  0.000661  0.000890  0.000526  0.000682   \n",
       "REP   0.000421  0.000747  0.000661  0.000911  0.000759  0.000449  0.000582   \n",
       "SAB   0.000566  0.001006  0.000890  0.000759  0.001633  0.000605  0.000784   \n",
       "TEF   0.000335  0.000595  0.000526  0.000449  0.000605  0.000653  0.000464   \n",
       "SAN   0.000434  0.000771  0.000682  0.000582  0.000784  0.000464  0.000900   \n",
       "BBVA  0.000448  0.000795  0.000704  0.000600  0.000808  0.000478  0.000620   \n",
       "\n",
       "          BBVA  \n",
       "ACX   0.000448  \n",
       "MEL   0.000795  \n",
       "MTS   0.000704  \n",
       "REP   0.000600  \n",
       "SAB   0.000808  \n",
       "TEF   0.000478  \n",
       "SAN   0.000620  \n",
       "BBVA  0.000970  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=df_r.shape[0]/float(df_r.shape[1])\n",
    "cov=df_r.cov()\n",
    "bWidth=0.25 \n",
    "\n",
    "dd=deNoiseCov(cov,q,bWidth)\n",
    "pd.DataFrame(index=cov.index, columns=cov.columns, data=dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering - algoritmo ONC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Función que clusteriza la matriz de correlaciones empleando el número óptimo de clusters. Para encontrar ese número \n",
    "óptimo de clusters se modifica el algoritmo de KMeans introduciendo el coeficiente de Silhouette como medida de la calidad\n",
    "del clustering.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    corr0 (array) -> matriz de correlaciones a clusterizar.\n",
    "    maxNumClusters (int) -> número máximo de clusters. Por defecto, la mitad del número de tickers.\n",
    "    n_init (int) -> \"número de veces que se ejecutará el algoritmo k-means con diferentes semillas de centroides. El \n",
    "                    resultado final será el mejor resultado de n_init ejecuciones consecutivas en términos de inercia\".\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    corr1 (dataframe) -> matriz de correlaciones ordenada en base al clustering realizado.\n",
    "    clstrs (diccionario) -> clusters encontrados junto con los tickers que pertenecen a cada cluster.\n",
    "    silh (serie) -> coeficiente de Silhouette asociado a cada ticker.\n",
    "'''\n",
    "def clusterKMeansBase(corr0,maxNumClusters=None,n_init=10): \n",
    "    \n",
    "    dist=((1-corr0.fillna(0))/2.)**.5 # distance matrix \n",
    "    silh=pd.Series()\n",
    "    \n",
    "    # Aleatoriedad controlada para que proporcione la misma solución en ejecuciones múltiples con los \n",
    "    # mismos datos de entrada:\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    if maxNumClusters is None:\n",
    "        maxNumClusters=int(corr0.shape[0]/2.)\n",
    "        \n",
    "    for init in range(n_init): \n",
    "        \n",
    "        # Buscamos el número óptimo de clusters:\n",
    "        for i in range(2,maxNumClusters+1): \n",
    "            \n",
    "            kmeans_=KMeans(n_clusters=i,n_jobs=1,n_init=1) \n",
    "            kmeans_=kmeans_.fit(dist)\n",
    "                       \n",
    "            # kmeans_.labels_ nos dice a qué cluster pertenece cada ticker\n",
    "            # silhouette_samples calcula el coeficiente de Silhouette para cada muestra\n",
    "            silh_=silhouette_samples(dist,kmeans_.labels_)\n",
    "            \n",
    "            # stat es q, una medida de la calidad del clustering, cuanto más grande, mejor\n",
    "            # stat[0] es el q obtenido con el nuevo i\n",
    "            # stat[1] es el mejor q obtenido hasta el momento\n",
    "            stat=(silh_.mean()/silh_.std(),silh.mean()/silh.std())\n",
    "            \n",
    "            # Si el q obtenido ahora (stat[0]) es mejor que el anterior, se actualiza:\n",
    "            if np.isnan(stat[1]) or stat[0]>stat[1]:\n",
    "                silh=silh_ \n",
    "                kmeans=kmeans_ \n",
    "        \n",
    "    newIdx=np.argsort(kmeans.labels_) \n",
    "    corr1=corr0.iloc[newIdx] # reorder rows \n",
    "    corr1=corr1.iloc[:,newIdx] # reorder columns \n",
    "    \n",
    "    clstrs={i:corr0.columns[np.where(kmeans.labels_==i)[0]].tolist() for \\\n",
    "            i in np.unique(kmeans.labels_)} # cluster members \n",
    "    silh=pd.Series(silh,index=dist.index)\n",
    "    \n",
    "    return corr1,clstrs,silh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           MEL       SAB       ACX       MTS       REP       TEF       SAN  \\\n",
       " MEL   0.001729  0.000974  0.000486  0.000809  0.000760  0.000438  0.000773   \n",
       " SAB   0.000974  0.001633  0.000515  0.000824  0.000748  0.000571  0.000924   \n",
       " ACX   0.000486  0.000515  0.000529  0.000604  0.000403  0.000272  0.000426   \n",
       " MTS   0.000809  0.000824  0.000604  0.001268  0.000691  0.000378  0.000710   \n",
       " REP   0.000760  0.000748  0.000403  0.000691  0.000911  0.000422  0.000628   \n",
       " TEF   0.000438  0.000571  0.000272  0.000378  0.000422  0.000653  0.000498   \n",
       " SAN   0.000773  0.000924  0.000426  0.000710  0.000628  0.000498  0.000900   \n",
       " BBVA  0.000778  0.000947  0.000441  0.000732  0.000609  0.000487  0.000827   \n",
       " \n",
       "           BBVA  \n",
       " MEL   0.000778  \n",
       " SAB   0.000947  \n",
       " ACX   0.000441  \n",
       " MTS   0.000732  \n",
       " REP   0.000609  \n",
       " TEF   0.000487  \n",
       " SAN   0.000827  \n",
       " BBVA  0.000970  ,\n",
       " {0: ['MEL', 'SAB'], 1: ['ACX', 'MTS', 'REP', 'TEF', 'SAN', 'BBVA']},\n",
       " ACX     0.468598\n",
       " MEL     0.122323\n",
       " MTS     0.207809\n",
       " REP     0.392142\n",
       " SAB     0.051466\n",
       " TEF     0.444141\n",
       " SAN     0.315064\n",
       " BBVA    0.267823\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov=df_r.cov()\n",
    "\n",
    "clusterKMeansBase(cov,maxNumClusters=int(cov.shape[0]/2),n_init=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio allocation - algoritmo NCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Función que calcula las ponderaciones de cartera de acuerdo al modelo de Markowitz considerando tanto posiciones\n",
    "largas como posiciones cortas. Consideraciones:\n",
    "    mu = None -> calcula las ponderaciones de cartera de la cartera de mínima varianza.\n",
    "    mu = rendimientos diarios medios -> calcula las ponderaciones de cartera de la cartera con el máximo ratio de Sharpe.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    cov (array) -> matriz de covarianzas a considerar.\n",
    "    mu (array) -> vector de rendimientos diarios medios.\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    w (array) -> vector con las ponderaciones de cartera asociadas a cada ticker.\n",
    "'''\n",
    "def optPort(cov,mu=None):\n",
    "    inv=np.linalg.inv(cov)\n",
    "    ones=np.ones(shape=(inv.shape[0],1))\n",
    "    if mu is None:mu=ones\n",
    "    w=np.dot(inv,mu)\n",
    "    w/=np.dot(ones.T,w) # es un array\n",
    "    return w \n",
    "\n",
    "'''\n",
    "Función que calcula las ponderaciones de cartera de la cartera de mínima varianza considerando únicamente posiciones largas.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    cov (array) -> matriz de covarianzas a considerar.\n",
    "    mu (array) -> vector de rendimientos diarios medios.\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    w (array) -> vector con las ponderaciones de cartera asociadas a cada ticker.\n",
    "'''\n",
    "def optPort_mv(cov):\n",
    "       \n",
    "    num_acciones = cov.shape[1]\n",
    "        \n",
    "    w = cp.Variable(num_acciones)\n",
    "    risk = cp.quad_form(w, cov)\n",
    "  \n",
    "    # Establecemos unos límites para el valor de w:    \n",
    "    w_max = 0.1\n",
    "    \n",
    "    # Si la cartera EW asigna unos pesos menores que la limitación deseada (w_max), podemos establecer ese límite:\n",
    "    if (1./num_acciones) <= w_max:        \n",
    "        prob = cp.Problem(cp.Minimize(risk), \n",
    "               [cp.sum(w) == 1, \n",
    "                w >= 0, w <= w_max])     \n",
    "    \n",
    "    # En caso contrario, no:\n",
    "    else:\n",
    "        prob = cp.Problem(cp.Minimize(risk), \n",
    "                       [cp.sum(w) == 1, \n",
    "                        w >= 0])  \n",
    "        \n",
    "    prob.solve()\n",
    "    sol=w.value\n",
    "    \n",
    "    return sol\n",
    "\n",
    "'''\n",
    "Función que calcula las ponderaciones de cartera de la cartera tangente considerando únicamente posiciones largas.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    cov (array) -> matriz de covarianzas a considerar.\n",
    "    mu (array) -> vector de rendimientos diarios medios.\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    w (array) -> vector con las ponderaciones de cartera asociadas a cada ticker.\n",
    "'''\n",
    "def optPort_sr(cov,mu): \n",
    "    \n",
    "    num_acciones=cov.shape[1]\n",
    "        \n",
    "    rf=0.0 # rf -> rentabilidad del activo libre de riesgo\n",
    "    def objetivo(w): #-SR\n",
    "        wM=np.array(w).reshape(len(w),1) \n",
    "        var=np.dot(np.dot(wM.T,cov),wM)\n",
    "        vol=np.sqrt(var[0][0])\n",
    "        rp_diario=np.dot(wM.T,mu)\n",
    "        sr=(rp_diario*252-rf)/(vol*np.sqrt(252)) # Valor anual del ratio de sharpe\n",
    "        return -sr[0][0] # Maximizar SR es lo mismo que minimizar -SR\n",
    "    \n",
    "    # Problema de optimización:    \n",
    "    w0=np.random.random(num_acciones)\n",
    "    w0=w0/np.sum(w0)\n",
    "    \n",
    "    # Establecemos unos límites para el valor de w:    \n",
    "    w_max = 0.1\n",
    "    \n",
    "    # Si la cartera EW asigna unos pesos menores que la limitación deseada (w_max), podemos establecer ese límite:\n",
    "    if (1./num_acciones) < w_max:        \n",
    "        b=(0.,w_max)\n",
    "    \n",
    "    # En caso contrario, no:\n",
    "    else:\n",
    "        b=(0.,1.)\n",
    "        \n",
    "    bnds=tuple(b for i in range(num_acciones))\n",
    "    \n",
    "    cons={'type': 'eq', 'fun': lambda w: sum(w)-1}\n",
    "    \n",
    "    sol=minimize(objetivo, w0, method='SLSQP', bounds=bnds, constraints=cons) \n",
    "\n",
    "    w=(sol.x) # es un array\n",
    "    \n",
    "    return w\n",
    "\n",
    "'''\n",
    "Función que calcula las ponderaciones de cartera de acuerdo con el algoritmo NCO. Consideraciones:\n",
    "    denoise = False -> valor por defecto. No se elimina el ruido de la matriz de correlaciones para la asignación de pesos.\n",
    "    denoise = True -> se elimina el ruido de la matriz de correlaciones para la asignación de pesos.\n",
    "\n",
    "DATOS DE ENTRADA:\n",
    "    df_r (dataframe) -> rendimientos diarios históricos de los tickers a considerar para la asignación de pesos.\n",
    "    bWidth (float) -> ancho de banda del núcleo. Por defecto 0.25.\n",
    "    maxNumClusters (int) -> número máximo de clusters. Por defecto la mitad del número de tickers.\n",
    "\n",
    "DATOS DE SALIDA:\n",
    "    df_w (serie) -> ponderaciones de cartera asociadas a cada ticker.\n",
    "'''\n",
    "# Los parámetros por defecto no hace falta indicarlos a la hora de llamar a la función!\n",
    "def nco(df_r,maxNumClusters=None,denoise=True):\n",
    "    \n",
    "    cov=df_r.cov()\n",
    "    mu=df_r.mean()\n",
    "    q=df_r.shape[0]/float(df_r.shape[1])\n",
    "    \n",
    "    # ETAPA 0:\n",
    "    # Si queremos eliminar el ruido de la matriz de covarianzas debemos hacerlo antes del clustering:\n",
    "    if denoise==True:\n",
    "        bWidth=0.25\n",
    "        dd=deNoiseCov(cov,q,bWidth)\n",
    "        cov=pd.DataFrame(index=cov.index, columns=cov.columns, data=dd)\n",
    "       \n",
    "    # ETAPA 1: \n",
    "    # Clusterizamos la matriz de covarianzas en subconjuntos de variables altamente correlacionadas recurriendo a la \n",
    "    # función clusterKMeansBase.\n",
    "    corr1=cov2corr(cov)\n",
    "    corr1,clstrs,_=clusterKMeansBase(corr1,maxNumClusters,n_init=10)\n",
    "    \n",
    "    # df que recogerá los pesos intra-cluster: \n",
    "    wIntra=pd.DataFrame(0,index=cov.index,columns=clstrs.keys())\n",
    "\n",
    "    # ETAPA 2:\n",
    "    # Asignamos los pesos dentro de cada cluster (intra-cluster allocations)\n",
    "    for i in clstrs:\n",
    "        # El .values convierte los valores del df en un array\n",
    "        cov_=cov.loc[clstrs[i],clstrs[i]].values\n",
    "        mu_=mu.loc[clstrs[i]].values.reshape(-1,1)\n",
    "        \n",
    "        # Pesos intra-cluster\n",
    "        #wIntra.loc[clstrs[i],i]=optPort(cov_,mu_).flatten()\n",
    "        wIntra.loc[clstrs[i],i]=optPort_sr(cov_,mu_).flatten()\n",
    "        #wIntra.loc[clstrs[i],i]=optPort_mv(cov_).flatten()\n",
    "    \n",
    "    # ETAPA 3:\n",
    "    # Asignamos los pesos a los clusters (inter-cluster allocations)    \n",
    "    cov_=wIntra.T.dot(np.dot(cov,wIntra)) # matriz de covarianzas reducida\n",
    "    \n",
    "    # Considerando que cada cluster forma una cartera, el rendimiento diario esperado para cada cluster será \n",
    "    # el rendimiento diario esperado para la cartera que forma: \n",
    "    mu_=wIntra.T.dot(mu)\n",
    "    \n",
    "    # Pesos inter-cluster\n",
    "    #wInter=pd.Series(optPort(cov_,mu_).flatten(),index=cov_.index)\n",
    "    wInter=pd.Series(optPort_sr(cov_.to_numpy(),mu_.to_numpy().reshape(-1,1)).flatten(),index=cov_.index)\n",
    "    #wInter=pd.Series(optPort_mv(cov_.values).flatten(),index=cov_.index)\n",
    "    \n",
    "    # Los pesos de cada ticker serán el resultado de multiplicar los pesos intra-cluster por los pesos inter-cluster:\n",
    "    nco=wIntra.mul(wInter,axis=1).sum(axis=1).values.reshape(-1,1)\n",
    "   \n",
    "    # El .flatten() devuelve una copia del array de pesos nco recogido todo en una sola dimensión\n",
    "    df_w=pd.Series(data=nco.flatten(),index=cov.columns)\n",
    "\n",
    "    return df_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados SIN reducir el ruido de la matriz de covarianzas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACX     9.020562e-17\n",
       "MEL     0.000000e+00\n",
       "MTS     1.000000e+00\n",
       "REP     1.298874e-16\n",
       "SAB     2.159731e-16\n",
       "TEF     0.000000e+00\n",
       "SAN     6.938894e-18\n",
       "BBVA    0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nco(df_r,denoise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados reduciendo el ruido de la matriz de covarianzas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACX     2.003862e-01\n",
       "MEL     0.000000e+00\n",
       "MTS     7.996138e-01\n",
       "REP     3.040103e-16\n",
       "SAB     3.211407e-16\n",
       "TEF     0.000000e+00\n",
       "SAN     0.000000e+00\n",
       "BBVA    0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nco(df_r,denoise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
